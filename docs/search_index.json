[["index.html", " Chapter 1 About this book", "  Zhoulvbang 2025-01-13 Chapter 1 About this book Markdown \\(\\alpha\\)=0.05 PandocMarkdown \\(a^2 + b^2 = c^2\\) Usage All knowledge is, in final analysis, history. All sciences are, in the abstact, mathematics. All judgements are, in their rationale, statistics.    C.R. Rao Statistics And Truth "],[".html", "Chapter 2  2.1 ", " Chapter 2  2.1  2.1.1   2.1.2           2.1.3            "],[".html", "Chapter 3  3.1  3.2  3.3  3.4  3.5 ", " Chapter 3  3.1  3.1.1         (1):\\(\\bar x\\) (2):\\(\\mu\\) (1)\\(\\bar X=\\frac{\\sum{X_{i}}}{n}\\) (2)\\(\\bar X = \\frac{\\sum{f_{i}X_{i}}}{\\sum{f}}\\)\\(X\\)\\(f\\) (1) (2)   \\(G\\) (1)\\(G=\\sqrt[n]{x_{1}·x_{2}·x_{3}\\cdots}x_{n}\\) (2)\\(G=\\ln^{-1}(\\frac{\\sum{f_{i}\\ln X_{i}}}{\\sum{f_{i}}})\\) (1) (2)    \\(M\\) (1)n\\(M=X_{\\frac{n+1}{x}}\\) n\\(M=\\frac{1}{2} (X_{\\frac{n}{2}}+X_{\\frac{n}{2}+1})\\) (2)\\(P_{X}=L_{X}+\\frac{i}{f_{x}}(nX\\%-\\sum{f_{i}})\\)    \\ (1) f\\(X\\)  3.1.2  \\(\\approx\\) \\(&gt;\\) \\(&lt;\\) 3.2  3.2.1        \\(X_{Max}-X_{Min}\\) \\(R\\) /  \\(IQR\\) \\(IQR=P_{75}-P_{25}\\)    \\(s^{2}\\) \\(\\sigma^{2}\\) \\(s^{2}=\\frac{\\sum(x_{i}-x)^2}{(n-1)}\\) ;   \\(s\\) \\(\\sigma\\) \\(s=\\sqrt{\\frac{\\sum(x_{i}-x)^2}{(n-1)}}\\)    \\(CV\\) \\(CV=\\frac{s}{\\bar x}×100%\\) (1)(2) 3.2.2 standard deviation  \\[s=\\sqrt{\\frac{\\sum\\limits_{i=1}^nx_i^2-\\frac{\\left(\\sum\\limits_{i=1}^nx_i\\right)^2}{n}}{n-1}}\\]  \\[s=\\sqrt{\\frac{\\sum\\limits_{k=1}^gf_kx_{mk}^2-\\left(\\sum\\limits_{k=1}^gf_kx_{mk}\\right)^2 \\left(\\sum\\limits_{k=1}^gf_k\\right)}{\\sum\\limits_{k=1}^gf_k-1}}\\] 3.3  3.3.1             \\(\\frac{A}{B}\\) \\(\\frac{}{}×100\\%\\) \\(\\frac{}{}×K\\) \\(\\frac{}{\\sum(×)}×K\\)        [0,1] [0,1] 1  RR,CV    3.3.2              3.3.3    -      3.4              notice \\(SMR=\\frac{}{}\\)  3.5  3.5.1              notice+ 3.5.2                          3.5.3  Choice of Statistical Charts "],[".html", "Chapter 4  4.1  4.2 ", " Chapter 4  4.1          nk                       &gt;&gt;&gt; &gt;&gt;&gt;  4.2                   "],[".html", "Chapter 5  5.1  5.2  5.3  5.4  5.5  5.6 Bayes", " Chapter 5  += 5.1  deterministic phenomenon random phenomenon \\(E\\) \\(\\omega\\)\\(E\\)\\(\\omega\\)\\(E\\)elementary event 5.2  ABBAAB\\(A\\supseteq B\\)\\(B\\subseteq A\\)\\(\\supseteq\\) \\(\\subseteq\\) AB\\(A\\supseteq B B\\supseteq A\\)AB\\(A=B\\) ABABAB\\(A\\cup B\\)\\(A+B\\) ABABAB\\(A\\cap B\\)\\(AB\\) ABAB\\(A-B\\) AB\\(A\\cup B=\\emptyset\\)AB AB\\(A\\cap B=\\emptyset A\\cup B=\\Omega\\)ABcomplementary events 5.3  frequencyEAEnmAn\\(m/n\\)AF(A) \\[F(A)=\\frac{m}{n}\\] probabilitynAmn\\(m/n\\)ppAP(A) \\[P(A)=p \\approx \\frac{m}{n}\\]    :A\\(P(A)\\geq 0\\) :\\(P(\\Omega)=1\\) :\\(P(\\bigcup \\limits_{i=1}^{\\infty}A_i)=\\sum \\limits_{i=1}^{\\infty}P(A_i)\\) 5.4  AB\\(\\Omega\\) \\[P(A+B)=P(A)+P(B)\\] AB A\\(\\bar A\\)\\(P(\\bar A)=1-P(A)\\) ABA \\[P(A+B)=P(A)+P(B)-P(AB)\\] AB\\(P(AB)=0\\) 5.5    ABconditional probability\\(P(B\\mid A)\\) \\[P(B\\mid A)=\\frac{P(AB)}{P(A)},P(A)&gt;0\\] ABA  \\[P(AB)=P(A)P(B\\mid A),P(A)&gt;0\\\\ P(AB)=P(B)P(A\\mid B),P(B)&gt;0\\]  BA\\(P(B\\mid A)=P(B)\\)BA\\(P(A\\mid B)=P(A)\\) \\(P(AB)=P(B)P(A\\mid B),P(B)&gt;0\\)AB \\[P(AB)=P(A)P(B)\\]  5.6 Bayes  \\(A_1,A_2,\\dots,A_n\\) \\(A_1,A_2,\\dots,A_n\\)\\(P(A_i)&gt;0(i=1,2,\\dots,n)\\); \\(A_1+A_2+\\dots+A_n=\\Omega\\) B \\[P(B)=\\sum_\\limits{i=1}^{n}P(A_i)P(B\\mid A_i)\\] total probability formulaB\\(A_i\\)B Bayes n\\(A_1,A_2,\\dots,A_n\\)B\\(A_k(k=1,2,\\dots,n)\\) \\[P(A_k\\mid B)=\\frac{P(A_k)P(B\\mid A_k)}{\\sum_\\limits{i=1}^{n}P(A_i)P(B\\mid A_i)},(k=1,2,\\dots,n),P(B)&gt;0\\] Bayes\\(P(A_k\\mid B)\\)(posterior probability)\\(P(A_k)\\)(prior probability) 5.6.1 Bayes          5.6.2 Bayes 8- -Bayes \\[PPV=\\frac{SE\\times P}{SE\\times P+(1-P)(1-SP)}\\] \\[NPV=\\frac{SP\\times (1-P)}{SP\\times (1-P)+(1-SE)\\times P}\\] PPVNPVSESPP : "],[".html", "Chapter 6  6.1 (Binomial Distribution) 6.2 (Poission Distribution) 6.3  6.4  6.5 (Normal Distribution) 6.6  6.7 ", " Chapter 6  type of data 6.1 (Binomial Distribution) \\(n\\)\\(X\\)\\(\\pi\\)\\(1-\\pi\\) \\(X\\)\\(\\mu_{x}=n\\pi\\) \\(\\sigma_{x}=n\\pi(1-\\pi)\\) notice \\(n=1\\)  Figure 6.1: Binomial Distribution with Different n/ 6.2 (Poission Distribution) \\(P(\\mu)\\)\\(n\\)\\(\\pi\\) \\(\\mu\\) \\(X\\sim P(\\mu_{1})\\)\\(Y\\sim P(\\mu_{2})\\)\\(X\\)\\(Y\\) \\(X+Y \\sim P(\\mu_{1}+\\mu_{1})\\) \\(\\lambda(\\mu)\\) \\(0\\)\\(+\\infty\\)1 \\(\\mu \\ge20\\) # Define the range for x x &lt;- 0:40 # Define the lambda values lambdas &lt;- c(1, 4, 10, 20) # Set up the plot area plot(x, dpois(x, lambdas[1]), type=&quot;n&quot;, ylim=c(0, max(dpois(x, lambdas))), xlab=&quot;x&quot;, ylab=&quot;Probability&quot;, main=&quot;Poisson Distribution with Different  Values&quot;) # Plot the Poisson distributions for each lambda colors &lt;- c(&quot;blue&quot;, &quot;green&quot;, &quot;red&quot;, &quot;purple&quot;) for (i in 1:length(lambdas)) { lines(x, dpois(x, lambdas[i]), type=&quot;b&quot;, pch=19, col=colors[i]) } # Add a legend legend(&quot;topright&quot;, legend=paste(&quot; =&quot;, lambdas), col=colors, pch=19) Figure 6.2: Poisson Distribution with Different =n 6.3   \\[ Pr(X=K)=\\frac{n!}{k!(n-k)!}\\pi^{k}(1-\\pi)^{n-k},k=0,1,2,3,\\cdots,n \\]  6.4   \\[ Pr(X=K)=\\frac{e^{-\\mu}\\mu^{k}}{k!},k=0,1,2,\\cdots \\]  library(ggplot2) library(cowplot) #  6.5 (Normal Distribution) 6.5.1  X \\[f(x)=\\frac{1}{\\sqrt{2\\pi\\sigma}}e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}, (-\\infty&lt;x&lt;+\\infty)\\] X\\(X\\sim N(\\mu,\\sigma^2)\\) Figure 6.3: Normal Curve comparsion (Normal Distribution)\\(X\\)\\(\\mu\\)\\(\\sigma\\)\\(X\\sim N(\\mu,\\sigma^{2})\\) Normal curve\\(\\mu\\)\\(\\sigma\\) Figure 6.4: Normal Curve    \\(\\mu\\)\\(\\sigma\\) \\(\\sigma\\)\\(\\mu\\)\\(X\\) \\(\\mu\\)\\(\\sigma\\)\\(X\\) \\(\\sigma\\)\\(\\to\\) \\(\\sigma\\)\\(\\to\\) X\\(N(\\mu_1,\\sigma_1^2)\\)Y\\(N(\\mu_2,\\sigma_2^2)\\)XY\\(X-Y\\)\\(N(\\mu_1-\\mu_2,\\sigma_1^2+\\sigma_2^2)\\) Figure 6.5: Different Normal Curve 6.6  U\\(\\varphi(u)\\) \\[\\varphi(u)=\\frac{1}{\\sqrt{2\\pi}}e^{-\\frac{u^2}{2}},(-\\infty&lt;x&lt;+\\infty)\\] Standard normal distribution\\(U\\)\\(Z\\)\\(X\\)01\\(X \\sim N(0,1)\\)   ZU 1Z  \\(Z = \\frac{X-\\mu}{\\sigma}\\) Z 2 \\(\\mu,\\sigma\\)\\(0,1\\) ## TableGrob (1 x 2) &quot;arrange&quot;: 2 grobs ## z cells name grob ## 1 1 (1-1,1-1) arrange gtable[layout] ## 2 2 (1-1,2-2) arrange gtable[layout] Figure 6.6: Normalized Transformation 6.6.1  68-95-99.7 Figure 6.7: Normal     Medical reference range   notice: \\(\\mu ±\\sigma\\) \\(X\\)\\(f(x)=\\frac{1}{2\\sqrt{p}}e^{\\frac{(x+2)^2}{4}}\\)\\(X\\)\\(\\mu\\)\\(\\frac{X-2}{\\sqrt{2}}\\)\\(f(x)=\\frac{1}{\\sigma \\sqrt{2\\pi}}e^{\\frac{-(x-\\mu)^2}{2\\sigma^2}}\\)\\(p=\\pi\\) 6.6.2  Figure 6.8: Skewed Curves notice   6.7  conversion relationship "],[".html", "Chapter 7  7.1 t 7.2 F 7.3 \\(\\chi^2\\)", " Chapter 7  7.1 t tuNormal Distribution \\(\\mu\\)\\(\\sigma\\)Xu\\([(X-\\mu)/\\sigma]\\)u\\(\\mu=0,\\sigma=1\\)(Standard Normal Distribution)u  n \\(N(\\mu,\\sigma)\\)u\\(N(0,1)\\) \\(\\sigma^2\\)()\\(s^2\\)()\\(\\sigma^2\\)u t  t  t  Figure 7.1: t-distribution Curves t  W.S. Gosset  1908  Student,   (Student)   t   7.2 F Figure 7.2: F-distribution Curves 7.2.1 F  variation between classesvariation within class   = +  =  +   =  +   7.3 \\(\\chi^2\\) Figure 7.3: Chi-square Distribution Curves 7.3.1     "],[".html", "Chapter 8  8.1  8.2  8.3  8.4  8.5 ", " Chapter 8  8.1  sufficient statistic 8.2  8.2.1 \\(\\bar X\\)   \\[\\bar X \\sim N(\\mu,\\sigma_{\\bar X}^2)\\] \\(\\bar X\\) \\[U=\\frac{\\bar X-\\mu}{\\sigma_{\\bar X}}=\\frac{\\bar X-\\mu}{\\sigma_ X/\\sqrt{n}}\\] U\\(U\\sim N(0,1)\\) \\((n\\geq30)\\)\\(\\bar X\\) (Central limit theorems):\\(X\\)\\(\\sigma^2(\\sigma^2\\neq0)\\)n\\(\\bar X\\)\\(\\mu\\)\\(\\sigma_{\\bar X}^2\\) \\[\\bar X\\simeq N(\\mu,\\frac{\\sigma^2}{n})\\] \\(S^2\\)\\(\\sigma^2\\)\\(S^2\\)\\(\\sigma^2\\) \\(n\\)\\(m\\)\\(m\\) 8.2.2 \\(S^2\\) \\[\\frac{(n-1)S^2}{\\sigma^2}\\sim \\chi^2(v)\\] \\(\\chi^2\\)F.R. Helmert1875 \\[f_v(x)=\\begin{cases} \\frac{1}{2^{\\frac{v}{2}}\\Gamma\\left(\\frac{v}{2}\\right)}y^{\\frac{v}{2}-1}\\mathrm{e}^{-\\frac{\\chi^2}{2}},&amp;\\chi^2&gt;0\\\\ 0,&amp;\\chi^2\\leq0\\end{cases}\\] \\(\\chi^2\\)\\(t\\) 8.2.3    \\(p\\) \\(\\mu_{p}=\\pi\\) \\(p\\) \\(\\sigma_p^2=\\frac{\\pi(1-\\pi)}{n}\\)();\\(S_p^2=\\frac{p(1-p)}{n}\\)() \\(p\\) \\(\\sigma_p=\\sqrt{\\frac{\\pi(1-\\pi)}{n}}\\)();\\(S_p=\\sqrt{\\frac{p(1-p)}{n}}\\)()  \\(\\sigma_p=\\sqrt{\\frac{\\pi(1-\\pi)}{n}}\\)();\\(S_p=\\sqrt{\\frac{p(1-p)}{n}}\\)() 8.2.4     \\(\\bar X=\\frac{\\sum_\\limits{i=1}^{n}X_i}{n}\\)  \\(\\sigma^2=\\frac{\\sum_\\limits{i=1}^{n}(\\mu-\\bar \\mu)^2}{n}\\)();\\(S^2=\\frac{\\sum_\\limits{i=1}^{n}(X_i-\\bar X)^2}{n-1}\\)() 1 (SE) \\(\\sigma_{\\bar X}=\\frac{\\sigma}{\\sqrt{n}}\\)();\\(S_{\\bar X}=\\frac{S}{\\sqrt{n}}\\)() (Law of large Numbers):   8.3  8.3.1  8.3.2  8.3.2.1 \\(\\mu\\)  t 8.3.2.2 \\(\\sigma^2\\) 8.4  8.5  \\(\\mu\\)\\(\\sigma^2\\)\\(n\\)\\(n\\) \\(\\pi\\)\\(n\\)\\(p\\)\\(n\\pi&gt;5\\)\\(n(1-\\pi)&gt;5\\)\\(p\\) :\\(S^2\\)n \\(\\sum_{i=1}^{n}(x_i-\\bar x)^2\\)\\(n-1\\)\\(\\bar x\\)\\(x_i(i=1,2,\\dots,n)\\)\\(n-1\\) "],[".html", "Chapter 9  9.1  9.2  9.3 ", " Chapter 9  9.1  Quantitative Data Analysis Steps Quantitative data difference test 9.2  Categorical Data Analysis Steps Categorical data difference test 9.3  9.3.1 1 SD60.2 ug/100g0.4 ug/100gSD  0.2 ug/100g 0.4 ug/100g d d2 1 2 3 4 5 1 84 108 -24 576 2 42 65 -23 529 3 70 94 -24 576 4 64 88 -24 576 5 65 92 -27 729 6 76 90 -14 196  -136 3182  1 2 3  1 2SD 3twilcoxon 9.3.2 2 6260×\\(\\chi^2\\)\\(\\chi^2=7.085\\)\\(P=-0.069\\)        21 18 12 11 62  11 13 16 20 60  32 31 28 31 122  1 2 3 4  1 2 3 4\\(wilcoxon\\)\\(Kruskal-Wallis H\\)  Z \\(P\\)\\(\\alpha\\) "],[".html", "Chapter 10  10.1  10.2  10.3 ", " Chapter 10  10.1  10.1.1         1.  2. 1. 2.  n n n0   n  1.  2. n 3. \\(\\sigma_{\\bar x}=\\frac{\\sigma}{\\sqrt{n}}\\),\\(\\sigma_{\\bar x}\\)\\(\\sigma\\)\\(\\sqrt{n}\\) 10.1.2      \\(\\mu\\)   1095%9.5,10.59.5,10.595% 95%3.6,6.195%3.6,6.1  1. nt2. n3. Z 1.  2.    1.  2.  3.  95%  10.2  95%95%× 95%95%× \\(1-\\alpha=95\\%\\)100955 95%95%× 95% 95%× 10.3  10.3.1  Confidence Level 95%99% Width of Confidence Interval  10.3.2  Sample Size  Sample Standard Deviation   95%99%   Point Estimate and Statistical Technique tztz "],[".html", "Chapter 11  11.1  11.2  11.3 ", " Chapter 11  11.1     1. \\(H_{0}:\\mu_{d}=0;H_{1}:\\mu_{d}\\neq 0,\\alpha=0.05\\) 2. \\(H_{0}:\\mu_{d}=0;H_{1}:\\mu_{d}&lt;0\\mu_{d}&gt;0,\\alpha=0.05\\) 1. 2.  3.   1. 2. \\(t\\)\\(\\chi^2\\)\\(F\\)3. \\(H_{0}\\) P 1. \\(P\\le \\alpha\\)\\(\\alpha\\)\\(H_{0}\\)\\(H_{1}\\)2. \\(P&gt;\\alpha\\)H0 \\(H_{0}\\)1. 2.  11.2   \\(H_{0}\\)\\(H_{1}\\) \\(H_{0}\\) \\(H_{0}\\) \\(\\textrm{I}\\)(\\(\\alpha\\))() \\(H_{0}\\) (\\(1-\\alpha\\)) \\(H_{0}\\) (\\(1-\\beta\\))\\(H_{1}\\)\\(H_{0}\\)\\(H_{1}\\)\\(1-\\beta\\) \\(\\textrm{II}\\)(\\(\\beta\\))()\\(H_{0}\\) 11.2.1 \\(1-\\beta\\) \\(\\alpha\\)\\(\\alpha\\) \\(H_{0}\\)\\(H_{1}\\)    11.2.2 \\(\\alpha \\beta 1-\\beta\\) \\(\\alpha\\)\\(\\beta\\)\\(1-\\beta\\)\\(\\alpha\\)\\(\\textrm{II}\\)\\(\\beta\\)\\(\\textrm{I}\\) \\(\\alpha\\)\\(\\beta\\) 11.3       \\((1-\\alpha)\\)\\((1-\\alpha)\\)  1.  1.  2. 3.   1. 2.  3.\\(1-\\alpha\\)4. \\(z&#39;\\)\\(\\alpha\\)\\(C=1-\\alpha\\)\\(\\alpha\\)\\(1-\\alpha\\) "],[".html", "Chapter 12  12.1  12.2 \\(t\\) 12.3 ", " Chapter 12  12.1   Parameter test Non-parameter tests  \\(\\rightarrow\\)? \\(\\rightarrow\\)?  \\(Z\\)\\(t\\)\\(F\\) Rank sum test  1. 2. 1. 2.    1. 2.   t 1. 2. 3. 4.   1. 2.  12.2 \\(t\\)  \\(t\\)  \\(N(\\mu,\\sigma^2)\\)n\\(\\bar x\\)\\(s\\)\\(t=\\frac{\\bar x-\\mu}{s_{\\bar x}}=\\frac{\\bar x-\\mu}{s/\\sqrt{n}}\\)\\(n-1\\)  0 \\(t\\)  \\(t\\)\\(-\\infty \\sim +\\infty\\)  \\(v=n-1\\) Figure 12.1: t-Distribution Curves vs. Standard Normal Curve 12.3  12.3.1        \\(H_0\\)\\(H_1\\) \\(H_0\\):\\(\\mu_1=\\mu_2=\\dots =\\mu_a\\)\\(H_1\\):\\(\\mu_1,\\mu_2,\\dots,\\mu_a\\)  \\(F=\\frac{MS_{}}{MS_{}}\\sim(v_{}=k-1v_{}=n-k\\)   12.3.2       \\(H_0\\)\\(H_1\\)  \\(H_0\\)\\(H_1\\)  \\(F=\\frac{MS_{}}{MS_{}}\\sim(v_{}=k-1,v_{}=(b-1)×(k-1))\\)\\(F=\\frac{MS_{}}{MS_{}}\\sim(v_{}=k-1,v_{}=(b-1)×(k-1))\\)   12.3.3  12.3.4         \\(H_0\\): \\(H_1\\):   \\(H_0\\): \\(H_1\\):   \\(F=\\frac{MS_{}}{MS_{}}\\sim F(v_{},v_{})\\)  - - -  "],[".html", "Chapter 13  13.1  13.2  13.3 ", " Chapter 13  13.1  13.1.1            Z \\(\\chi^2\\)Fisher R×C\\(\\chi^2\\)Fisher \\(\\chi^2\\)R×R\\(\\chi^2\\) /  Wilcoxon wilcoxon Kruskal-Wallis H Wilcoxon Friedman M 13.1.2     1. \\(\\pi_0\\)0.52. (1)k\\(Pr(X\\le k)\\)(2)k\\(Pr(X\\ge k)\\)  1. \\(n\\pi,n(1-\\pi)\\)52. \\(p-\\pi_0\\) noticep\\(\\pi_0\\)n 13.2  13.2.1 2×2\\(\\chi^2\\)     \\(n\\ge 40\\)\\(T\\ge 5\\)\\(n\\ge 40\\)\\(1\\le T&lt; 5\\)\\(n&lt;40\\)\\(T&lt;1\\) Fisher  \\(n_1p_1,n_1(1-p_1),n_2p_2,n_2(1-p_2)\\)5 \\(S_{p1-p2}\\)\\(p_c=\\frac{x_1+x_2}{n_1+n_2}\\)  \\(n_1p_1,n_1(1-p_1),n_2p_2,n_2(1-p_2)\\) +2+4 notice  1  \\(n_R\\)\\(n_C\\)n\\(T_{RC}=\\frac{n_R×n_C}{n}\\) \\(\\chi^2\\)\\(\\chi^2=\\sum \\frac{(A-T)^2}{T}\\) \\(\\chi^2\\)\\(\\chi^2=\\sum \\frac{(|A-T|-0.5)^2}{T}\\) 13.2.2 \\(\\chi^2\\)     \\((b+c)\\ge 40\\)\\((b+c)&lt;40\\)  R×R\\(\\chi^2\\) R\\(R\\ge2\\) \\(T=\\frac{k-1}{k}\\sum_{i=1}^{k}\\frac{(n_i-m_i)^2}{n_i+m_i-2A_{ii}}\\) notice \\(\\chi^2\\)\\(\\chi^2=\\sum \\frac{(A-T)^2}{T}=\\frac{(b-c)^2}{b+c}\\) b+c&lt;40,\\(\\chi^2\\)\\(\\chi^2=\\sum \\frac{(|b-c|-1)^2}{b+c}\\) 13.3  13.3.1 2×2  \\(H_0\\): \\(H_1\\): \\(\\alpha=0.05\\)  \\[\\chi^2=\\sum_{i,j}\\frac{(A_{ij}-T_{ij})^2}{T_{ij}} \\] P  \\[r=\\sqrt{\\frac{\\chi^2}{\\chi^2+n}}\\] 13.3.2 2×2 13.3.3 R×C    \\(H_0\\)\\(H_1\\)  \\(v=(R-1)(C-1)\\)  1. 11/515 2. Fisher  \\(H_0\\)R×C\\(\\alpha\\) notice: RR\\(\\chi^2\\)42\\(v=(R-1)×(C-1)=(4-1)(2-1)=3\\) \\(\\chi^2\\)\\(1/5\\)5\\(1\\le T\\le5\\) "],[".html", "Chapter 14  14.1 ", " Chapter 14  14.1  Rank-Sum Test  Mann-Whitney U Wilcoxon Wilcoxon t 14.1.1  Mann-Whitney U   \\(X\\)  \\(Y\\) \\(n_1\\)  \\(n_2\\)  \\(R_1\\)  \\(R_2\\) $ X$  \\(Y\\)  T  \\(n_1&lt;n_2\\)\\(n_1\\)\\(T_1\\)\\(T\\)\\(T\\)2 10\\(H_0\\)\\(T\\) \\[T\\approx N\\left(\\frac{n_1(n+1)}{2},\\frac{n_1 n_2(n+1)}{12} \\right)\\] Wilcoxon \\(H_0\\)\\(\\mu=\\frac{n_1(n+1)}{2}\\) \\(T\\) \\[U=\\frac{T-\\frac{n_1(n+1)}{2}+C}{\\sqrt{\\frac{n_1 n_2(n+1)}{12}}}\\approx N(0,1)\\] C\\(T&gt;\\frac{n(n+1)}{4}\\)\\(C=-0.5\\)\\(T&lt;\\frac{n(n+1)}{4}\\)\\(C=0.5\\)\\(T=\\frac{n(n+1)}{4}\\)\\(C=0\\) &gt;25% \\[U_c=\\frac{T-\\frac{n_1(n+1)}{2}+C}{\\sqrt{\\frac{n_1 n_2}{12}[(n+1)-\\sum_\\limits{i=1}^{g}\\frac{t_i^3-t_i}{n(n-1)}]}}\\approx N(0,1)\\] Wilcoxon   \\((X_i, Y_i)\\) \\(D_i = X_i - Y_i\\)0 \\(R_i\\) \\(W\\) \\[W = \\sum R_i \\cdot \\text{sign}(D_i)\\]  \\(T\\)  \\(W\\)   \\(n\\ge 30\\)\\(H_0\\)\\(T\\) \\[T\\approx N \\left(\\frac{n(n+1)}{4},\\frac{n(n+1)(2n+1)}{24}\\right)\\] \\(\\mu=\\frac{n(n+1)}{4}\\)\\(\\sigma^2=\\frac{n(n+1)(2n+1)}{24}\\) T \\[U=\\frac{T-\\frac{n(n+1)}{4}+C}{\\sqrt{\\frac{n(n+1)(2n+1)}{24}}}\\approx N(0,1)\\] n0C\\(T&gt;\\frac{n(n+1)}{4}\\)\\(C=-0.5\\)\\(T&lt;\\frac{n(n+1)}{4}\\)\\(C=0.5\\)\\(T=\\frac{n(n+1)}{4}\\)\\(C=0\\) N25% \\[U=\\frac{T-\\frac{n(n+1)}{4}+C}{\\sqrt{\\frac{n(n+1)(2n+1)}{24}-\\frac{\\sum_\\limits{i=1}^g(t_i^3-t_i)}{48}}}\\approx N(0,1)\\] \\(t_i\\)\\(i\\)\\(g\\) Wilcoxon notice3 14.1.2  Mann-Whitney U     Wilcoxon     14.1.3  t  \\(U&lt;u_{\\alpha/2}\\)\\(H_0\\)\\(U&gt;u_{1-\\alpha/2}\\)\\(H_0\\)  Wilcoxon  "],[".html", "Chapter 15  15.1  15.2  15.3  15.4 ", " Chapter 15  15.1  two variables relationship 15.2  15.2.1  The basic process of straight-line regression analysis 15.2.2    Pearson \\(\\rightarrow\\)\\(\\rightarrow\\)t  \\(\\rightarrow\\)\\(\\rightarrow\\) Spearman \\(\\rightarrow\\)+\\(\\rightarrow\\) 15.3  15.3.1  Draw a scatterplot 15.3.2  \\(\\alpha\\)\\(\\beta\\)ab \\[\\hat y=a+bx\\] \\((x_i,y_i)\\) least squares estimation \\[ \\begin{cases} a=\\bar y-b \\bar x\\\\ b=\\frac{\\sum\\limits_{i=1}^n x_i y_i - \\frac{1}{n}(\\sum\\limits_{i=1}^n x_i)(\\sum\\limits_{i=1}^n y_i)}{\\sum\\limits_{i=1}^n x_i^2 - \\frac{1}{n}(\\sum\\limits_{i=1}^n x_i)^2} \\end{cases} \\]  \\[ SS_{xx}=\\sum_{i}(x_i-\\bar x)^2=\\sum_{i}x_i^2-\\frac{1}{n}(\\sum_{i}x_i)^2\\\\ SS_{yy}=\\sum_{i}(y_i-\\bar y)^2=\\sum_{i}y_i^2-\\frac{1}{n}(\\sum_{i}y_i)^2\\\\ SS_{xy}=\\sum_{i}(x_i-\\bar x)(y_i-\\bar y)=\\sum_{i}x_i y_i-\\frac{1}{n}(\\sum_{i}x_i)(\\sum_{i}y_i) \\] \\(SS_{xx}\\)\\(SS_{yy}\\)\\(SS_{xy}\\)  \\[ \\begin{cases} a=\\bar y-b \\bar x\\\\ b=\\frac{SS_{xy}}{SS_{xx}} \\end{cases} \\] 15.3.3  F \\(y_i\\) \\[SS_{yy}=\\sum_{i}(y_i-\\bar y)^2\\]  \\[SS_{yy}=\\sum_{i}^{n}(\\hat y_i-\\bar y)^2+\\sum_{i}^{n}(y_i-\\hat y_i)^2\\] \\(\\sum_{i}^{n}(\\hat y_i-\\bar y)^2\\)regression sum of squares\\(SS_R\\)\\(\\hat y_i\\)\\(\\bar y\\) \\[ \\begin{align} SS_{yy} &amp;= \\sum_{i=1}^{n}(\\hat y_i - \\bar y)^2 \\\\ &amp;= \\sum_{i=1}^{n}[a + bx_i - (a + b\\bar x)]^2 \\\\ &amp;= SS_{xx}b^2 \\\\ &amp;= SS_{xy}b \\end{align} \\] \\(SS_{R}\\)yxy\\(SS_R\\) \\(\\sum_{i}^{n}(y_i-\\hat y_i)^2\\)residual sum of squares\\(SS_E\\)\\(y_i\\)\\(\\hat y_i\\) \\[SS_E=\\sum_{i=1}^{n}(y_i-\\hat y_i)^2\\] \\(SS_E\\)xyxyyyx\\(SS_E\\)  \\[\\begin{align} SS_{yy}=&amp;\\sum_{i}^{n}(\\hat y_i-\\bar y)^2+\\sum_{i}^{n}(y_i-\\hat y_i)^2\\\\ =&amp;SS_R+SS_E \\end{align}\\] \\(v\\) \\[v_{yy}=v_R+v_E\\\\ v_{yy}=n-1,v_R=1,v_E=n-2\\] \\(H_0\\) \\[\\frac{SS_R}{\\sigma^2}\\sim \\chi^2(v_R),\\frac{SS_E}{\\sigma^2}\\sim \\chi^2(v_E)\\] \\(SS_R\\)\\(SS_E\\)  \\[F=\\frac{SS_R/v_R}{SS_E/v_E}\\] \\(v_R=1,v_E=n-2\\)Fyx\\(SS_R\\)\\(SS_E\\)F \\(\\alpha\\) \\(F&gt;F_{(v_R,v_E),1-\\alpha}\\)\\(H_0\\) \\(F\\leq F_{(v_R,v_E),1-\\alpha}\\)\\(H_0\\) t 15.4       1. X,Y\\(\\textrm{II}\\)X2. YXXXY  1. XY2. YX  1. r2. bXY rb rbY/X \\(-1 \\le r \\le 1\\),\\(-\\infty&lt;b&lt;+\\infty\\) rb \\(r=\\frac{l_{xy}}{\\sqrt{l_{xx}l_{yy}}}\\),\\(b=\\frac{l_{xy}}{l_{xx}}\\)   rb  \\(t_b=t_r\\)  \\(b=r\\frac{S_Y}{S_X}\\)\\(S_X,S_Y\\)\\(X,Y\\)  \\(R^2=\\frac{SS_{}}{SS_{}}\\)\\(R^2\\)1 notice  \\((X, Y) \\sim N(\\mu, \\Sigma)\\) \\(\\mu\\) \\(\\Sigma\\)   1.  $(X, Y)$ \\[\\mu = \\begin{pmatrix} \\mu_X \\\\ \\mu_Y \\end{pmatrix}\\]  \\(\\mu_X\\)  \\(\\mu_Y\\)  \\(X\\)  \\(Y\\)  2.  \\[\\Sigma = \\begin{pmatrix} \\sigma_X^2 &amp; \\sigma_{XY} \\\\ \\sigma_{XY} &amp; \\sigma_Y^2 \\end{pmatrix}\\]  \\(\\sigma_X^2\\)  \\(\\sigma_Y^2\\)  \\(X\\)  \\(Y\\) \\(\\sigma_{XY}\\)    $X$  $Y$    $X$ $Y$    X  Y  $\\sigma_{XY} &gt; 0$ $\\sigma_{XY} &lt; 0$   \\(X\\)  \\(Y\\) \\((X, Y)\\)    \\[\\mu = \\begin{pmatrix} 170 \\\\ 65 \\end{pmatrix}\\]  170  65    \\[\\Sigma = \\begin{pmatrix} 100 &amp; 20 \\\\ 20 &amp; 25 \\end{pmatrix}\\]  100 25 20  180   ##  #install.packages(&quot;plotly&quot;) #install.packages(&quot;mvtnorm&quot;) #library(plotly) #library(mvtnorm) #  x &lt;- seq(150, 190, length.out = 100) #150-190100 y &lt;- seq(50, 80, length.out = 100) #50-80100 grid &lt;- expand.grid(X = x, Y = y) # x  y  #  mu &lt;- c(170, 65) # 170 cm  65 kg sigma &lt;- matrix(c(100, 20, 20, 25), nrow = 2) # 100 25 20 #  z &lt;- dmvnorm(as.matrix(grid), mean = mu, sigma = sigma) # #  z_matrix &lt;- matrix(z, nrow = 100, ncol = 100) #  plot_ly(x = x, y = y, z = z_matrix, type = &quot;surface&quot;) %&gt;% layout(title = list(text = &quot;&quot;, y=0.95), scene = list(xaxis = list(title = &quot; (cm)&quot;), yaxis = list(title = &quot; (kg)&quot;), zaxis = list(title = &quot;&quot;))) Figure 15.1: Binary normal distribution "],[".html", "Chapter 16  16.1 2024.09.25", " Chapter 16  16.1 2024.09.25 extractpastenotion   extractnotion Rmarkdown   neat and repeat  "],["usage.html", "Chapter 17 Usage() 17.1 Render book() 17.2 Preview book() 17.3 R+Rstudio 17.4 Rmarkdown 17.5 options 17.6 vscodermarkdown 17.7 Rmarkdown 17.8 ", " Chapter 17 Usage()  bookdown  .Rmd  .Rmd   #  ##   ###  index.Rmd   my_book_project/  index.Rmd  01-chapter1.Rmd  02-chapter2.Rmd  _bookdown.yml  _output.yml 17.1 Render book()  HTML   RStudio IDE  Build   Build Book All formats  R  bookdown::render_book()  bookdown::pdf_book \\(XeLaTeX\\) TinyTeX \\(XeLaTeX\\)https://yihui.org/tinytex/ \\(TeX\\)TeXLiveMaCTeXTeXLiveLaTeX:TeXLive2021MaCTeX notice:248RstudioKnit one by one could not find ggplot functionConsolebookdown::render_book(\"index.Rmd\")Set Working Directory 17.2 Preview book()  HTML  .Rmd  RStudio  Preview book  R  bookdown::serve_book() 17.3 R+Rstudio RR··RRSSchemeRCFORTRANR rmarkdownRRstudioR pageR R RstudioRR scriptvscodermarkdownRstudio macOSRRstudio NoticemacOSIntelARMCPUARMM1/M2 17.4 Rmarkdown GitHubrmarkdown 17.4.1 bookdown # from CRAN install.packages(&#39;rmarkdown&#39;) or # install from GitHub devtools::install_github(&#39;rstudio/rmarkdown&#39;) 17.4.2 setload bookdown library(rmarkdown) 17.4.3  PDFLaTeXLaTeXR MarkdownTinyTeX install.packages(&#39;tinytex&#39;) tinytex::install_tinytex() TinyTexYihui XieR MarkdownLatexLaTeXRtinytexLaTeXR MarkdownPDFLaTeXLaTeX TeXLiveWindows or LinuxMacTeXmacOS 17.4.4 bookdown  RstudioFile-&gt;New Project-&gt;New Directory-&gt;Bookproject using bookdown-&gt;Create Project  R Markdown YAML: R MarkdownYAMLYAML Aint Markup LanguageR Markdowntitleauthordateoutput formatYAML --- title: &quot;&quot; author: &quot;&quot; date: &quot;2024-06-08&quot; output: html_document --- Markdown: MarkdownR MarkdownMarkdownMarkdown #   - 1 - 2 1. 1 2. 2 &gt;  : R MarkdownMarkdownR MarkdownRPythonSQLR python section 17.5 options {r,options} 17.5.1  eval: eval=FALSE, include: include=FALSE echo: echoMarkdownecho=TRUEmarkdown collapse: collapse=TRUE prompt: prompt=TRUER&gt; comment#comment='' results: results= markupHTML; hide; hold asisHTMLRHTMLknitrkable()HTML 17.5.2  warningwarning=FALSE errorerror=FALSE messagemessage=FALSEmessage 17.5.3  R Markdownknitr::opts_chunk$setYAML  # knitr knitr::opts_chunk$set( echo = TRUE, #  eval = TRUE, # highlight = TRUE, # warning = FALSE, #  message = FALSE, #  fig.width = 7, #  fig.height = 5 #  ) Notice 17.6 vscodermarkdown vscodeR Extension for Visual Studio CodevscodeRvscodeRstudioGitHubrmarkdownGitHubGitHub/ 17.6.1 R extension vscodeEXTENSIONSsearchR install Rextension 17.6.2  vscodeRRstudioPDFR Markdown1.12.3Pandoc [VSC-R] index.Rmd process started ==&gt; rmarkdown::render_site(&#39;/Users/uesrname/uesrname.github.io/index.Rmd&#39;) Error: pandoc version 1.12.3 or higher is required and was not found (see the help page ?rmarkdown::pandoc_available). In addition: Warning message: In verify_rstudio_version() : Please install or upgrade Pandoc to at least version 1.17.2; or if you are using RStudio, you can just install RStudio 1.0+. Execution halted 17.6.2.1 Pandoc PandocPandoc Windowspandocs download page Macpandocs download pagehomebrewbrew install pandocPandoc 17.6.2.2 Pandoc PandocPandoc which pandocPandoc 17.6.2.3 Pandoc PandocR Markdownrmarkdown::render()pandocPandoc rmarkdown::render(\"index.Rmd\", pandoc=\"/path/to/pandoc\") Pandocvscode.htmlvscodeoutputoutput Output created: docs/index.html Output created: /Users/username/username.github.io/docs/index.html &lt;&lt;&lt;vsc&gt;&gt;&gt;docs/index.html&lt;&lt;&lt;vsc&gt;&gt;&gt; [VSC-R] index.Rmd process exited with exit code null index.html RStudioRStudioPandocRstudioPDFLaTeX RStudio  Tools -&gt; Global Options -&gt; Sweave  Sweave Pandoc 17.7 Rmarkdown /gridea Academic pagejerkllInternetGitHub22~ post~ ~ RRmarkdown~ ··· MSOFFICEWord LaTeX\\(LaTeX\\)\\(LaTeX\\) RamrkdownxieyihuimarkdownLaTeXhtmlmarkdown\\(LaTeX\\)RRmarkdown 17.8   `r if (knitr::is_html_output()) &#39; # References {-} &#39; "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
